{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [sample solution that works]\n",
    "\n",
    "# This tutorial is will bring you through your first deep reinforcement learning model\n",
    "\n",
    "\n",
    "* Seaquest game as an example\n",
    "* Training a simple lasagne neural network for Q_learning objective\n",
    "\n",
    "\n",
    "## About OpenAI Gym\n",
    "\n",
    "* Its a recently published platform that basicly allows you to train agents in a wide variety of environments with near-identical interface.\n",
    "* This is twice as awesome since now we don't need to write a new wrapper for every game\n",
    "* Go check it out!\n",
    "  * Blog post - https://openai.com/blog/openai-gym-beta/\n",
    "  * Github - https://github.com/openai/gym\n",
    "\n",
    "\n",
    "## New to Lasagne and AgentNet?\n",
    "* We only require surface level knowledge of theano and lasagne, so you can just learn them as you go.\n",
    "* Alternatively, you can find Lasagne tutorials here:\n",
    " * Official mnist example: http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    " * From scratch: https://github.com/ddtm/dl-course/tree/master/Seminar4\n",
    " * From theano: https://github.com/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb\n",
    "* This is pretty much the basic tutorial for AgentNet, so it's okay not to know it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "\n",
    "#game title. full list of games = http://yavar.naddaf.name/ale/list_of_current_games.html\n",
    "GAME=\"alien\"\n",
    "\n",
    "#game image will be resized from (210,160) to your image_size. \n",
    "#You may want a bigger image for your homework assignment IF you want a larger NN\n",
    "IMAGE_W,IMAGE_H = IMAGE_SIZE =(105,80)\n",
    "\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 10\n",
    "SEQ_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"floatX=float32\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%env THEANO_FLAGS=\"floatX=float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3ce87b0cd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM8AAAD/CAYAAABW+4LyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neBTFk/8P0fSAkr4okZsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3cee9535d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from env import Atari\n",
    "\n",
    "#creating a game\n",
    "atari = Atari(GAME,image_size=IMAGE_SIZE) \n",
    "\n",
    "action_names = np.array(atari.get_action_meanings())\n",
    "\n",
    "obs = atari.step(0)[0]\n",
    "\n",
    "plt.imshow(obs,interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using simple convolutional neural network.\n",
    "\n",
    "![scheme](https://s18.postimg.org/gbmsq6gmx/dqn_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer, DimshuffleLayer,ExpressionLayer\n",
    "\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,IMAGE_W,IMAGE_H,3))\n",
    "\n",
    "observation_grayscale = ExpressionLayer(observation_layer,\n",
    "                                        lambda a: a.mean(axis=-1),\n",
    "                                        output_shape=lambda shape: shape[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.memory import WindowAugmentation,LSTMCell,RNNCell\n",
    "\n",
    "#store 4-tick window in order to perceive motion of objects\n",
    "\n",
    "prev_window = InputLayer([None,2,IMAGE_W,IMAGE_H])\n",
    "\n",
    "current_window = WindowAugmentation(observation_grayscale,prev_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import Conv2DLayer,Pool2DLayer,DenseLayer,batch_norm,dropout\n",
    "\n",
    "#main neural network body\n",
    "conv0 = Conv2DLayer(current_window,16,filter_size=(8,8),stride=(4,4),name='conv0')\n",
    "\n",
    "conv1 = Conv2DLayer(batch_norm(conv0),32,filter_size=(4,4),stride=(2,2),name='conv1')\n",
    "\n",
    "conv2 = Conv2DLayer(batch_norm(conv1),64,filter_size=(4,4),stride=(2,2),name='conv2')\n",
    "\n",
    "dense0 = DenseLayer(batch_norm(conv2),256,name='dense',nonlinearity = lasagne.nonlinearities.tanh)\n",
    "\n",
    "#please set this to your last layer for convenience\n",
    "last_layer = dense0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a layer that predicts Qvalues\n",
    "qvalues_layer = DenseLayer(last_layer,\n",
    "                   num_units = atari.action_space.n,\n",
    "                   nonlinearity=lasagne.nonlinearities.linear,\n",
    "                   name=\"q-evaluator layer\")\n",
    "\n",
    "#To pick actions, we use an epsilon-greedy resolver (epsilon is a property)\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer,name=\"e-greedy action picker\")\n",
    "\n",
    "action_layer.epsilon.set_value(np.float32(0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=qvalues_layer,\n",
    "              agent_states={current_window:prev_window},\n",
    "              action_layers=action_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[conv0.W,\n",
       " conv0_bn.beta,\n",
       " conv0_bn.gamma,\n",
       " conv1.W,\n",
       " conv1_bn.beta,\n",
       " conv1_bn.gamma,\n",
       " conv2.W,\n",
       " conv2_bn.beta,\n",
       " conv2_bn.gamma,\n",
       " dense.W,\n",
       " dense.b,\n",
       " q-evaluator layer.W,\n",
       " q-evaluator layer.b]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pool import AtariGamePool\n",
    "\n",
    "pool = AtariGamePool(agent,GAME, N_AGENTS,image_size=IMAGE_SIZE,max_size=100) #may need to adjust for speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LEFTFIRE' 'DOWNFIRE' 'DOWNFIRE' 'DOWNFIRE' 'DOWNFIRE' 'DOWNFIRE'\n",
      "  'DOWNFIRE']\n",
      " ['LEFTFIRE' 'DOWNFIRE' 'DOWNFIRE' 'DOWNFIRE' 'DOWNFIRE' 'DOWNFIRE'\n",
      "  'DOWNFIRE']]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "CPU times: user 472 ms, sys: 780 ms, total: 1.25 s\n",
      "Wall time: 445 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(7)\n",
    "\n",
    "\n",
    "print(action_names[action_log][:2])\n",
    "print(reward_log[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,qvalues_seq = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    optimize_experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "#crop rewards to [-1,+1] to avoid explosion.\n",
    "#import theano.tensor as T\n",
    "#rewards = T.maximum(-1,T.minimum(rewards,1))\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=0.99,)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adadelta(loss,weights,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-08 11:01:38,125] Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\n",
      "[2016-11-08 11:01:38,126] Clearing 4 monitor files from previous run (because force=True was provided)\n",
      "[2016-11-08 11:01:38,185] Starting new video recorder writing to /home/main/notebooks/records/openaigym.video.0.916.video000000.mp4\n",
      "[2016-11-08 11:01:46,681] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/main/notebooks/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 665 timesteps with reward=130.0\n"
     ]
    }
   ],
   "source": [
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"<the link to mp4 file from the cell above>\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "video_path=\"<the link to mp4 file from the cell above>\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {epoch_counter:untrained_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10\tepsilon=0.496\treward/step=0.36000\n",
      "iter=20\tepsilon=0.491\treward/step=0.26000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "for i in xrange(10**10):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    for i in range(1): #you may want to increase the number of training iterations per one update\n",
    "        loss = train_step()\n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    current_epsilon = 0.05 + 0.45*np.exp(-epoch_counter/1000.)\n",
    "    action_layer.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    if epoch_counter%10==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = pool.experience_replay.rewards.get_value().mean()\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\"%(epoch_counter,\n",
    "                                                         current_epsilon,\n",
    "                                                         pool_mean_reward))\n",
    "        \n",
    "\n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%100 ==0:\n",
    "        rewards[epoch_counter] = pool.evaluate(record_video=False)\n",
    "        \n",
    "        plt.title(\"random frames\")\n",
    "        for i in range(min((len(pool.games),6))):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.imshow(pool.games[i].get_observation())\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(*zip(*sorted(list(rewards.items()),key=lambda p:p[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_layer.epsilon.set_value(0.001)\n",
    "rw = pool.evaluate(n_games=20,save_path=\"./records\",record_video=False)\n",
    "print(\"mean session score=%f.5\"%rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "#select the one you want\n",
    "video_path=\"./records/openaigym.video.0.13.video000000.mp4\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Once you got it working,\n",
    "Try building a network that maximizes the final score\n",
    "\n",
    "* Moar lasagne stuff: convolutional layers, batch normalization, nonlinearities and so on\n",
    "* Recurrent agent memory layers, GRUMemoryLayer, etc\n",
    "* Different reinforcement learning algorithm (p.e. qlearning_n_step), other parameters\n",
    "* Experience replay pool\n",
    "\n",
    "\n",
    "Look for info?\n",
    "* [lasagne doc](http://lasagne.readthedocs.io/en/latest/)\n",
    "* [agentnet doc](http://agentnet.readthedocs.io/en/latest/)\n",
    "* [gym homepage](http://gym.openai.com/)\n",
    "\n",
    "\n",
    "You can also try to expand to a different game: \n",
    " * all OpenAI Atari games are already compatible, you only need to change GAME_TITLE\n",
    " * Other discrete action space environments are also accessible this way\n",
    " * For continuous action spaces, either discretize actions or use continuous RL algorithms (e.g. .learning.dpg_n_step)\n",
    " * Adapting to a custom non-OpenAI environment can be done with a simple wrapper\n",
    " \n",
    " \n",
    "__Good luck!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
