{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [sample solution that works]\n",
    "\n",
    "# This tutorial is will bring you through your first deep reinforcement learning model\n",
    "\n",
    "\n",
    "* Seaquest game as an example\n",
    "* Training a simple lasagne neural network for Q_learning objective\n",
    "\n",
    "\n",
    "## About OpenAI Gym\n",
    "\n",
    "* Its a recently published platform that basicly allows you to train agents in a wide variety of environments with near-identical interface.\n",
    "* This is twice as awesome since now we don't need to write a new wrapper for every game\n",
    "* Go check it out!\n",
    "  * Blog post - https://openai.com/blog/openai-gym-beta/\n",
    "  * Github - https://github.com/openai/gym\n",
    "\n",
    "\n",
    "## New to Lasagne and AgentNet?\n",
    "* We only require surface level knowledge of theano and lasagne, so you can just learn them as you go.\n",
    "* Alternatively, you can find Lasagne tutorials here:\n",
    " * Official mnist example: http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    " * From scratch: https://github.com/ddtm/dl-course/tree/master/Seminar4\n",
    " * From theano: https://github.com/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb\n",
    "* This is pretty much the basic tutorial for AgentNet, so it's okay not to know it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "\n",
    "#game title. full list of games = http://yavar.naddaf.name/ale/list_of_current_games.html\n",
    "GAME=\"alien\"\n",
    "\n",
    "#game image will be resized from (210,160) to your image_size. \n",
    "#You may want a bigger image for your homework assignment IF you want a larger NN\n",
    "IMAGE_W,IMAGE_H = IMAGE_SIZE =(105,80)\n",
    "\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 10\n",
    "SEQ_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"floatX=float32\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%env THEANO_FLAGS=\"floatX=float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5be0e52c10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAAD/CAYAAABSDlLPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+f/qljuEZXJ20gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5be0ed9f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from env import Atari\n",
    "\n",
    "#creating a game\n",
    "atari = Atari(GAME,image_size=IMAGE_SIZE) \n",
    "\n",
    "action_names = np.array(atari.get_action_meanings())\n",
    "\n",
    "obs = atari.step(0)[0]\n",
    "\n",
    "plt.imshow(obs,interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using simple convolutional neural network.\n",
    "\n",
    "![scheme](https://s18.postimg.org/gbmsq6gmx/dqn_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer, DimshuffleLayer,ExpressionLayer\n",
    "\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,IMAGE_W,IMAGE_H,3))\n",
    "\n",
    "observation_grayscale = ExpressionLayer(observation_layer,\n",
    "                                        lambda a: a.mean(axis=-1),\n",
    "                                        output_shape=lambda shape: shape[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.memory import WindowAugmentation,LSTMCell,RNNCell\n",
    "\n",
    "#store 4-tick window in order to perceive motion of objects\n",
    "\n",
    "prev_window = InputLayer([None,4,IMAGE_W,IMAGE_H])\n",
    "\n",
    "current_window = WindowAugmentation(observation_grayscale,prev_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import Conv2DLayer,Pool2DLayer,DenseLayer,batch_norm,dropout\n",
    "\n",
    "#main neural network body\n",
    "conv0 = Conv2DLayer(current_window,16,filter_size=(8,8),stride=(4,4),name='conv0')\n",
    "\n",
    "conv1 = Conv2DLayer(batch_norm(conv0),32,filter_size=(4,4),stride=(2,2),name='conv1')\n",
    "\n",
    "conv2 = Conv2DLayer(batch_norm(conv1),64,filter_size=(4,4),stride=(2,2),name='conv2')\n",
    "\n",
    "dense0 = DenseLayer(batch_norm(conv2),256,name='dense',nonlinearity = lasagne.nonlinearities.tanh)\n",
    "\n",
    "#please set this to your last layer for convenience\n",
    "last_layer = dense0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a layer that predicts Qvalues\n",
    "qvalues_layer = DenseLayer(last_layer,\n",
    "                   num_units = atari.action_space.n,\n",
    "                   nonlinearity=lasagne.nonlinearities.linear,\n",
    "                   name=\"q-evaluator layer\")\n",
    "\n",
    "#To pick actions, we use an epsilon-greedy resolver (epsilon is a property)\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer,name=\"e-greedy action picker\")\n",
    "\n",
    "action_layer.epsilon.set_value(np.float32(0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=qvalues_layer,\n",
    "              agent_states={current_window:prev_window},\n",
    "              action_layers=action_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[conv0.W,\n",
       " conv0_bn.beta,\n",
       " conv0_bn.gamma,\n",
       " conv1.W,\n",
       " conv1_bn.beta,\n",
       " conv1_bn.gamma,\n",
       " conv2.W,\n",
       " conv2_bn.beta,\n",
       " conv2_bn.gamma,\n",
       " dense.W,\n",
       " dense.b,\n",
       " q-evaluator layer.W,\n",
       " q-evaluator layer.b]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "[2016-11-01 01:02:35,664] We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    }
   ],
   "source": [
    "from pool import AtariGamePool\n",
    "\n",
    "pool = AtariGamePool(agent,GAME, N_AGENTS,image_size=IMAGE_SIZE,max_size=1000) #may need to adjust for speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DOWNLEFT' 'LEFTFIRE' 'LEFTFIRE' 'LEFTFIRE' 'LEFTFIRE' 'LEFTFIRE'\n",
      "  'LEFTFIRE']\n",
      " ['DOWNLEFT' 'LEFTFIRE' 'LEFTFIRE' 'LEFTFIRE' 'LEFTFIRE' 'LEFTFIRE'\n",
      "  'LEFTFIRE']]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "CPU times: user 1.24 s, sys: 508 ms, total: 1.75 s\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(7)\n",
    "\n",
    "\n",
    "print(action_names[action_log][:2])\n",
    "print(reward_log[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,qvalues_seq = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    optimize_experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "#crop rewards to [-1,+1] to avoid explosion.\n",
    "#import theano.tensor as T\n",
    "#rewards = T.maximum(-1,T.minimum(rewards,1))\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions,\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=0.99,)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adadelta(loss,weights,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-01 01:06:35,155] Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\n",
      "[2016-11-01 01:06:35,157] Creating monitor directory ./records\n",
      "[2016-11-01 01:06:35,293] Starting new video recorder writing to /home/jheuristic/Downloads/dqn_binder/records/openaigym.video.0.11586.video000000.mp4\n",
      "[2016-11-01 01:07:27,421] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/jheuristic/Downloads/dqn_binder/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1405 timesteps with reward=860.0\n"
     ]
    }
   ],
   "source": [
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.0.13.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "video_path=\"<the link to mp4 file from the cell above>\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {epoch_counter:untrained_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10\tepsilon=0.496\treward/step=0.45455\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "for i in xrange(10**10):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    for i in range(5):\n",
    "        loss = train_step()\n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    current_epsilon = 0.05 + 0.45*np.exp(-epoch_counter/1000.)\n",
    "    action_layer.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    if epoch_counter%10==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = pool.experience_replay.rewards.get_value().mean()\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\"%(epoch_counter,\n",
    "                                                         current_epsilon,\n",
    "                                                         pool_mean_reward))\n",
    "        \n",
    "\n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%100 ==0:\n",
    "        rewards[epoch_counter] = pool.evaluate(record_video=False)\n",
    "        \n",
    "        plt.title(\"random frames\")\n",
    "        for i in range(min((len(pool.games),6))):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.imshow(pool.games[i].get_observation())\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(*zip(*sorted(list(rewards.items()),key=lambda p:p[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_layer.epsilon.set_value(0.001)\n",
    "rw = pool.evaluate(n_games=20,save_path=\"./records\",record_video=False)\n",
    "print(\"mean session score=%f.5\"%rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "#select the one you want\n",
    "video_path=\"./records/openaigym.video.0.13.video000000.mp4\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Once you got it working,\n",
    "Try building a network that maximizes the final score\n",
    "\n",
    "* Moar lasagne stuff: convolutional layers, batch normalization, nonlinearities and so on\n",
    "* Recurrent agent memory layers, GRUMemoryLayer, etc\n",
    "* Different reinforcement learning algorithm (p.e. qlearning_n_step), other parameters\n",
    "* Experience replay pool\n",
    "\n",
    "\n",
    "Look for info?\n",
    "* [lasagne doc](http://lasagne.readthedocs.io/en/latest/)\n",
    "* [agentnet doc](http://agentnet.readthedocs.io/en/latest/)\n",
    "* [gym homepage](http://gym.openai.com/)\n",
    "\n",
    "\n",
    "You can also try to expand to a different game: \n",
    " * all OpenAI Atari games are already compatible, you only need to change GAME_TITLE\n",
    " * Other discrete action space environments are also accessible this way\n",
    " * For continuous action spaces, either discretize actions or use continuous RL algorithms (e.g. .learning.dpg_n_step)\n",
    " * Adapting to a custom non-OpenAI environment can be done with a simple wrapper\n",
    " \n",
    " \n",
    "__Good luck!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
